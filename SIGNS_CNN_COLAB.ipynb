{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SIGNS_CNN_COLAB.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mohammad-Rahmdel/SIGNS_Recognition_Using_Tensorflow/blob/master/SIGNS_CNN_COLAB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hmYyZwS9E4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install PyDrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukdfRY8fvVms",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2tT5qrYwM1i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozJOiRxRva3-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir datasets \n",
        "\n",
        "download = drive.CreateFile({'id': '1fCmaeQyBWf9RFsaGdRYiAG-BypTzN8Nu'})\n",
        "download.GetContentFile('datasets/test_signs.h5')\n",
        "\n",
        "download = drive.CreateFile({'id': '1nU3KQ7fdTcfHNgY8jk9xbhqYlxDcWiiu'})\n",
        "download.GetContentFile('datasets/train_signs.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taLQjIjK-glp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops\n",
        "\n",
        "def load_dataset():\n",
        "  \n",
        "    train_dataset = h5py.File('./datasets/train_signs.h5', \"r\")\n",
        "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
        "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
        "\n",
        "    test_dataset = h5py.File('./datasets/test_signs.h5', \"r\")\n",
        "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
        "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
        "\n",
        "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
        "    \n",
        "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
        "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
        "    \n",
        "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n",
        "\n",
        "\n",
        "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
        "    \"\"\"\n",
        "    Creates a list of random minibatches from (X, Y)\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input data, of shape (input size, number of examples) (m, Hi, Wi, Ci)\n",
        "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples) (m, n_y)\n",
        "    mini_batch_size - size of the mini-batches, integer\n",
        "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
        "    \n",
        "    Returns:\n",
        "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
        "    \"\"\"\n",
        "    \n",
        "    m = X.shape[0]                  # number of training examples\n",
        "    mini_batches = []\n",
        "    np.random.seed(seed)\n",
        "    \n",
        "    # Step 1: Shuffle (X, Y)\n",
        "    permutation = list(np.random.permutation(m))\n",
        "    shuffled_X = X[permutation,:,:,:]\n",
        "    shuffled_Y = Y[permutation,:]\n",
        "\n",
        "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
        "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
        "    for k in range(0, num_complete_minibatches):\n",
        "        mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:,:,:]\n",
        "        mini_batch_Y = shuffled_Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:]\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "    \n",
        "    # Handling the end case (last mini-batch < mini_batch_size)\n",
        "    if m % mini_batch_size != 0:\n",
        "        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m,:,:,:]\n",
        "        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size : m,:]\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "    \n",
        "    return mini_batches\n",
        "\n",
        "\n",
        "def convert_to_one_hot(Y, C):\n",
        "    Y = np.eye(C)[Y.reshape(-1)].T\n",
        "    return Y\n",
        "\n",
        "\n",
        "def forward_propagation_for_predict(X, parameters):\n",
        "    \"\"\"\n",
        "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
        "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
        "                  the shapes are given in initialize_parameters\n",
        "    Returns:\n",
        "    Z3 -- the output of the last LINEAR unit\n",
        "    \"\"\"\n",
        "    \n",
        "    # Retrieve the parameters from the dictionary \"parameters\" \n",
        "    W1 = parameters['W1']\n",
        "    b1 = parameters['b1']\n",
        "    W2 = parameters['W2']\n",
        "    b2 = parameters['b2']\n",
        "    W3 = parameters['W3']\n",
        "    b3 = parameters['b3'] \n",
        "                                                           # Numpy Equivalents:\n",
        "    Z1 = tf.add(tf.matmul(W1, X), b1)                      # Z1 = np.dot(W1, X) + b1\n",
        "    A1 = tf.nn.relu(Z1)                                    # A1 = relu(Z1)\n",
        "    Z2 = tf.add(tf.matmul(W2, A1), b2)                     # Z2 = np.dot(W2, a1) + b2\n",
        "    A2 = tf.nn.relu(Z2)                                    # A2 = relu(Z2)\n",
        "    Z3 = tf.add(tf.matmul(W3, A2), b3)                     # Z3 = np.dot(W3,Z2) + b3\n",
        "    \n",
        "    return Z3\n",
        "\n",
        "def predict(X, parameters):\n",
        "    \n",
        "    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n",
        "    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n",
        "    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n",
        "    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n",
        "    W3 = tf.convert_to_tensor(parameters[\"W3\"])\n",
        "    b3 = tf.convert_to_tensor(parameters[\"b3\"])\n",
        "    \n",
        "    params = {\"W1\": W1,\n",
        "              \"b1\": b1,\n",
        "              \"W2\": W2,\n",
        "              \"b2\": b2,\n",
        "              \"W3\": W3,\n",
        "              \"b3\": b3}\n",
        "    \n",
        "    x = tf.placeholder(\"float\", [12288, 1])\n",
        "    \n",
        "    z3 = forward_propagation_for_predict(x, params)\n",
        "    p = tf.argmax(z3)\n",
        "    \n",
        "    sess = tf.Session()\n",
        "    prediction = sess.run(p, feed_dict = {x: X})\n",
        "        \n",
        "    return prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvqkqBU9-5r-",
        "colab_type": "code",
        "outputId": "f6a173cf-644f-4a4c-e53b-4c1e1a603de8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        }
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "from PIL import Image\n",
        "from scipy import ndimage\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops\n",
        "\n",
        "\n",
        "np.random.seed(1)\n",
        "\n",
        "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
        "\n",
        "# # Example of a picture\n",
        "# index = 21\n",
        "# plt.imshow(X_train_orig[index])\n",
        "# print (\"y = \" + str(np.squeeze(Y_train_orig[:, index])))\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "\n",
        "X_train = X_train_orig/255.\n",
        "X_test = X_test_orig/255.\n",
        "Y_train = convert_to_one_hot(Y_train_orig, 6).T\n",
        "Y_test = convert_to_one_hot(Y_test_orig, 6).T\n",
        "\n",
        "conv_layers = {}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.009,\n",
        "          num_epochs = 100, minibatch_size = 64, print_cost = True, lambd=0.0, keep_prob=1):\n",
        "    \"\"\"\n",
        "    Implements a three-layer ConvNet in Tensorflow:\n",
        "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
        "    \n",
        "    Arguments:\n",
        "    X_train (None, 64, 64, 3)\n",
        "    Y_train (None, n_y = 6)\n",
        "    X_test  (None, 64, 64, 3)\n",
        "    Y_test  (None, n_y = 6)\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
        "    tf.set_random_seed(1)                             \n",
        "    seed = 3                                          \n",
        "    (m, n_H0, n_W0, n_C0) = X_train.shape             \n",
        "    n_y = Y_train.shape[1]                            \n",
        "    costs = []  \n",
        "    train_acc = []\n",
        "    test_acc = []                                   \n",
        "\n",
        "\n",
        "    X = tf.placeholder(shape=[None, n_H0, n_W0, n_C0], dtype=tf.float32, name = 'X')\n",
        "    Y = tf.placeholder(shape=[None, n_y], dtype=tf.float32, name = 'Y')\n",
        "\n",
        "\n",
        "    tf.set_random_seed(1)                        \n",
        "    W1 = tf.get_variable(\"W1\", [4,4,3,8], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
        "    W2 = tf.get_variable(\"W2\", [2,2,8,16], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
        "\n",
        "\n",
        "    s = 1\n",
        "    Z1 = tf.nn.conv2d(X, W1, strides = [1,s,s,1], padding = 'SAME')\n",
        "    A1 = tf.nn.relu(Z1)\n",
        "    f = s = 8 # f = window size\n",
        "    P1 = tf.nn.max_pool(A1, ksize = [1,f,f,1], strides = [1,s,s,1], padding = 'SAME')\n",
        "\n",
        "\n",
        "    s = 1\n",
        "    Z2 = tf.nn.conv2d(P1, W2, strides = [1,s,s,1], padding = 'SAME')\n",
        "    A2 = tf.nn.relu(Z2)\n",
        "    f = s = 4\n",
        "    P2 = tf.nn.max_pool(A2, ksize = [1,f,f,1], strides = [1,s,s,1], padding = 'SAME')\n",
        "\n",
        "    # FLATTEN\n",
        "    P2 = tf.contrib.layers.flatten(P2)\n",
        "\n",
        "    # FULLY-CONNECTED without non-linear activation function (not call softmax).\n",
        "    # 6 neurons in output layer. \"activation_fn=None\" \n",
        "    Z3 = tf.contrib.layers.fully_connected(P2, num_outputs=6, activation_fn=None)\n",
        "    Z3 = tf.nn.dropout(Z3, keep_prob)\n",
        "\n",
        "    \"\"\"\n",
        "    In the last function above (tf.contrib.layers.fully_connected), the fully connected layer automatically \n",
        "    initializes weights in the graph and keeps on training them as you train the model. Hence, you did not need \n",
        "    to initialize those weights when initializing the parameters.\n",
        "    \"\"\"\n",
        "\n",
        " \n",
        "    cost = tf.nn.softmax_cross_entropy_with_logits(logits = Z3, labels = Y) + lambd * tf.nn.l2_loss(W1) + lambd * tf.nn.l2_loss(W2)\n",
        "    cost = tf.reduce_mean(cost)\n",
        "    \n",
        "    \n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "    \n",
        "    # Initialize all the variables globally\n",
        "    init = tf.global_variables_initializer() \n",
        "    # Start the session to compute the tensorflow graph\n",
        "    with tf.Session() as sess:\n",
        "        # Run the initialization\n",
        "        sess.run(init)\n",
        "        for epoch in range(num_epochs):\n",
        "            minibatch_cost = 0.\n",
        "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
        "            seed = seed + 1\n",
        "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
        "\n",
        "            for minibatch in minibatches:\n",
        "                (minibatch_X, minibatch_Y) = minibatch\n",
        "                _ , temp_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
        "            \n",
        "                minibatch_cost += temp_cost / num_minibatches\n",
        "\n",
        "\n",
        "\n",
        "            if print_cost == True and epoch % 5 == 0:\n",
        "                print (\"Cost after epoch %i: %f\" % (epoch, minibatch_cost))\n",
        "            if print_cost == True and epoch % 1 == 0:\n",
        "                costs.append(minibatch_cost)\n",
        "\n",
        "\n",
        "            if epoch % 10 == 0 :\n",
        "                predict_op = tf.argmax(Z3, 1)\n",
        "                correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
        "                \n",
        "                # Calculate accuracy on the test set\n",
        "                accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "                train_acc.append(accuracy.eval({X: X_train, Y: Y_train}))\n",
        "                test_acc.append(accuracy.eval({X: X_test, Y: Y_test}))\n",
        "            \n",
        "        _, ax = plt.subplots()\n",
        "        ax.plot(np.squeeze(train_acc), '-b', label='train accuracy')\n",
        "        ax.plot(np.squeeze(test_acc), '-r', label='test accuracy')\n",
        "        plt.ylabel('accuracy')\n",
        "        plt.xlabel('iterations (per tens)')\n",
        "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "        plt.show()\n",
        "             \n",
        "\n",
        "        \n",
        "        \n",
        "        \n",
        "        # # plot the cost\n",
        "        # plt.plot(np.squeeze(costs))\n",
        "        # plt.ylabel('cost')\n",
        "        # plt.xlabel('iterations (per tens)')\n",
        "        # plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "        # plt.show()\n",
        "\n",
        "        # Calculate the correct predictions\n",
        "        predict_op = tf.argmax(Z3, 1)\n",
        "        correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
        "        \n",
        "        # Calculate accuracy on the test set\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "        train_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n",
        "        test_accuracy = accuracy.eval({X: X_test, Y: Y_test})\n",
        "        print(\"Train Accuracy:\", train_accuracy)\n",
        "        print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "    \n",
        "model(X_train, Y_train, X_test, Y_test, learning_rate = 0.003, num_epochs = 120, \n",
        "      minibatch_size = 32, print_cost = True, lambd = 0.001, keep_prob=0.9)\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost after epoch 0: 1.873255\n",
            "Cost after epoch 5: 1.728289\n",
            "Cost after epoch 10: 1.087133\n",
            "Cost after epoch 15: 0.866747\n",
            "Cost after epoch 20: 0.736680\n",
            "Cost after epoch 25: 0.626305\n",
            "Cost after epoch 30: 0.574208\n",
            "Cost after epoch 35: 0.542627\n",
            "Cost after epoch 40: 0.453274\n",
            "Cost after epoch 45: 0.439011\n",
            "Cost after epoch 50: 0.410424\n",
            "Cost after epoch 55: 0.376274\n",
            "Cost after epoch 60: 0.357062\n",
            "Cost after epoch 65: 0.344419\n",
            "Cost after epoch 70: 0.321533\n",
            "Cost after epoch 75: 0.319679\n",
            "Cost after epoch 80: 0.320514\n",
            "Cost after epoch 85: 0.331128\n",
            "Cost after epoch 90: 0.281599\n",
            "Cost after epoch 95: 0.257652\n",
            "Cost after epoch 100: 0.281862\n",
            "Cost after epoch 105: 0.266236\n",
            "Cost after epoch 110: 0.256997\n",
            "Cost after epoch 115: 0.244683\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy: 0.91851854\n",
            "Test Accuracy: 0.84166664\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}