{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Signs_ResNet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mohammad-Rahmdel/SIGNS_Recognition_Using_Tensorflow/blob/master/Signs_ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtACd1BJkwOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install PyDrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORQ2dL0lk7ok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzHs6aTOk_CP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9puqCuRlDcV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8bba99c7-a6b9-4919-afc4-369e52675e2d"
      },
      "source": [
        "download = drive.CreateFile({'id': '1xuS1YLQsb-_83euwThUwsq4WFdB3ri7H'})\n",
        "download.GetContentFile('resnets_utils.py')\n",
        "\n",
        "\n",
        "\n",
        "!mkdir datasets \n",
        "\n",
        "download = drive.CreateFile({'id': '1fCmaeQyBWf9RFsaGdRYiAG-BypTzN8Nu'})\n",
        "download.GetContentFile('datasets/test_signs.h5')\n",
        "\n",
        "download = drive.CreateFile({'id': '1nU3KQ7fdTcfHNgY8jk9xbhqYlxDcWiiu'})\n",
        "download.GetContentFile('datasets/train_signs.h5')\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘datasets’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jshKsOM4lJ7j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1927
        },
        "outputId": "ed889828-9721-4779-e80b-00d6491029d1"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, Dropout\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils import plot_model\n",
        "from resnets_utils import *\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)\n",
        "\n",
        "\n",
        "from keras import regularizers\n",
        "\n",
        "\n",
        "\n",
        "def identity_block(X, f, filters, stage, block, lambd=0.0):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block as defined in Figure 3\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', \n",
        "    kernel_initializer = glorot_uniform(seed=0), kernel_regularizer=regularizers.l2(lambd))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path \n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', \n",
        "    kernel_initializer = glorot_uniform(seed=0), kernel_regularizer=regularizers.l2(lambd))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', \n",
        "    kernel_initializer = glorot_uniform(seed=0), kernel_regularizer=regularizers.l2(lambd))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step\n",
        "    X = Add()([X,X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X\n",
        "\n",
        "\n",
        "\n",
        "def convolutional_block(X, f, filters, stage, block, s = 2, lambd=0.0):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block as defined in Figure 4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    X_shortcut = X\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0), \n",
        "    kernel_regularizer=regularizers.l2(lambd))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path \n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', \n",
        "    kernel_initializer = glorot_uniform(seed=0), kernel_regularizer=regularizers.l2(lambd))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path\n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', \n",
        "    kernel_initializer = glorot_uniform(seed=0), kernel_regularizer=regularizers.l2(lambd))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "\n",
        "    ##### SHORTCUT PATH #### \n",
        "    X_shortcut = Conv2D(filters = F3, kernel_size = (1, 1), strides = (s,s), padding = 'valid', name = conv_name_base + '1', \n",
        "    kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step\n",
        "    X = Add()([X,X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    return X\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def ResNet50(input_shape = (64, 64, 3), classes = 6, lambd=0.0, keep_prob=1.0):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, kernel_size = (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0), \n",
        "    kernel_regularizer=regularizers.l2(lambd))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1, lambd=lambd)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b', lambd=lambd)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c', lambd=lambd)\n",
        "\n",
        "    # Stage 3 \n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2, lambd=lambd)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b', lambd=lambd)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c', lambd=lambd)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d', lambd=lambd)\n",
        "\n",
        "    # Stage 4 \n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2, lambd=lambd)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b', lambd=lambd)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c', lambd=lambd)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d', lambd=lambd)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e', lambd=lambd)\n",
        "\n",
        "    # Stage 5 \n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2, lambd=lambd)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c', lambd=lambd)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='d', lambd=lambd)\n",
        "\n",
        "    # AVGPOOL \n",
        "    X = AveragePooling2D(pool_size=(2,2), name='avg_pool')(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dropout(keep_prob)(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "model = ResNet50(input_shape = (64, 64, 3), classes = 6, lambd=1e-5, keep_prob=0.9)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
        "\n",
        "# Normalize image vectors\n",
        "X_train = X_train_orig/255.\n",
        "X_test = X_test_orig/255.\n",
        "\n",
        "# Convert training and test labels to one hot matrices\n",
        "Y_train = convert_to_one_hot(Y_train_orig, 6).T\n",
        "Y_test = convert_to_one_hot(Y_test_orig, 6).T\n",
        "\n",
        "\n",
        "\n",
        "model.fit(X_train, Y_train, epochs = 50, batch_size = 32)\n",
        "\n",
        "preds = model.evaluate(X_train, Y_train)\n",
        "print (\"Test Accuracy = \" + str(preds[1]))\n",
        "\n",
        "preds = model.evaluate(X_test, Y_test)\n",
        "print (\"Test Accuracy = \" + str(preds[1]))\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1080/1080 [==============================] - 78s 72ms/step - loss: 4.0394 - acc: 0.2194\n",
            "Epoch 2/50\n",
            "1080/1080 [==============================] - 4s 3ms/step - loss: 1.7994 - acc: 0.4083\n",
            "Epoch 3/50\n",
            "1080/1080 [==============================] - 4s 4ms/step - loss: 1.1494 - acc: 0.6269\n",
            "Epoch 4/50\n",
            "1080/1080 [==============================] - 4s 4ms/step - loss: 1.0140 - acc: 0.7213\n",
            "Epoch 5/50\n",
            "1080/1080 [==============================] - 4s 4ms/step - loss: 0.6788 - acc: 0.8213\n",
            "Epoch 6/50\n",
            "1080/1080 [==============================] - 4s 4ms/step - loss: 0.5121 - acc: 0.8796\n",
            "Epoch 7/50\n",
            "1080/1080 [==============================] - 4s 4ms/step - loss: 0.3528 - acc: 0.9444\n",
            "Epoch 8/50\n",
            "1080/1080 [==============================] - 4s 4ms/step - loss: 0.4291 - acc: 0.9130\n",
            "Epoch 9/50\n",
            "1080/1080 [==============================] - 4s 4ms/step - loss: 0.3477 - acc: 0.9389\n",
            "Epoch 10/50\n",
            "1080/1080 [==============================] - 4s 4ms/step - loss: 0.4073 - acc: 0.9222\n",
            "Epoch 11/50\n",
            "1080/1080 [==============================] - 4s 4ms/step - loss: 0.3407 - acc: 0.9463\n",
            "Epoch 12/50\n",
            "1080/1080 [==============================] - 4s 4ms/step - loss: 0.3293 - acc: 0.9565\n",
            "Epoch 13/50\n",
            "1080/1080 [==============================] - 4s 4ms/step - loss: 0.2793 - acc: 0.9657\n",
            "Epoch 14/50\n",
            "1080/1080 [==============================] - 4s 4ms/step - loss: 0.3517 - acc: 0.9417\n",
            "Epoch 15/50\n",
            "1080/1080 [==============================] - 4s 4ms/step - loss: 0.3907 - acc: 0.9380\n",
            "Epoch 16/50\n",
            "1080/1080 [==============================] - 4s 4ms/step - loss: 0.7169 - acc: 0.8324\n",
            "Epoch 17/50\n",
            "1080/1080 [==============================] - 4s 4ms/step - loss: 0.3520 - acc: 0.9306\n",
            "Epoch 18/50\n",
            "1080/1080 [==============================] - 4s 4ms/step - loss: 0.3177 - acc: 0.9519\n",
            "Epoch 19/50\n",
            "1080/1080 [==============================] - 4s 4ms/step - loss: 0.3516 - acc: 0.9481\n",
            "Epoch 20/50\n",
            "1080/1080 [==============================] - 4s 4ms/step - loss: 0.4049 - acc: 0.9222\n",
            "Epoch 21/50\n",
            "1080/1080 [==============================] - 4s 4ms/step - loss: 0.2802 - acc: 0.9574\n",
            "Epoch 22/50\n",
            "1080/1080 [==============================] - 4s 3ms/step - loss: 0.3120 - acc: 0.9611\n",
            "Epoch 23/50\n",
            "1080/1080 [==============================] - 4s 4ms/step - loss: 0.2591 - acc: 0.9667\n",
            "Epoch 24/50\n",
            "1080/1080 [==============================] - 4s 3ms/step - loss: 0.1931 - acc: 0.9880\n",
            "Epoch 25/50\n",
            "1080/1080 [==============================] - 4s 3ms/step - loss: 0.1877 - acc: 0.9926\n",
            "Epoch 26/50\n",
            "1080/1080 [==============================] - 4s 3ms/step - loss: 0.1622 - acc: 0.9991\n",
            "Epoch 27/50\n",
            "1080/1080 [==============================] - 4s 3ms/step - loss: 0.1767 - acc: 0.9954\n",
            "Epoch 28/50\n",
            "1080/1080 [==============================] - 4s 3ms/step - loss: 0.2159 - acc: 0.9880\n",
            "Epoch 29/50\n",
            "1080/1080 [==============================] - 4s 3ms/step - loss: 0.1671 - acc: 0.9972\n",
            "Epoch 30/50\n",
            "1080/1080 [==============================] - 4s 3ms/step - loss: 0.1630 - acc: 0.9972\n",
            "Epoch 31/50\n",
            "1080/1080 [==============================] - 4s 4ms/step - loss: 0.2143 - acc: 0.9852\n",
            "Epoch 32/50\n",
            "1080/1080 [==============================] - 4s 4ms/step - loss: 0.2407 - acc: 0.9750\n",
            "Epoch 33/50\n",
            "1080/1080 [==============================] - 4s 4ms/step - loss: 0.2325 - acc: 0.9824\n",
            "Epoch 34/50\n",
            "1080/1080 [==============================] - 4s 4ms/step - loss: 0.2174 - acc: 0.9843\n",
            "Epoch 35/50\n",
            "1080/1080 [==============================] - 4s 4ms/step - loss: 0.1767 - acc: 0.9954\n",
            "Epoch 36/50\n",
            "1080/1080 [==============================] - 4s 4ms/step - loss: 0.1725 - acc: 0.9954\n",
            "Epoch 37/50\n",
            "1080/1080 [==============================] - 4s 4ms/step - loss: 0.1830 - acc: 0.9954\n",
            "Epoch 38/50\n",
            "1080/1080 [==============================] - 4s 4ms/step - loss: 0.2028 - acc: 0.9833\n",
            "Epoch 39/50\n",
            "1080/1080 [==============================] - 4s 4ms/step - loss: 0.4277 - acc: 0.9333\n",
            "Epoch 40/50\n",
            "1080/1080 [==============================] - 4s 4ms/step - loss: 0.3491 - acc: 0.9417\n",
            "Epoch 41/50\n",
            "1080/1080 [==============================] - 4s 4ms/step - loss: 0.2507 - acc: 0.9704\n",
            "Epoch 42/50\n",
            "1080/1080 [==============================] - 4s 4ms/step - loss: 0.2196 - acc: 0.9833\n",
            "Epoch 43/50\n",
            "1080/1080 [==============================] - 4s 4ms/step - loss: 0.2056 - acc: 0.9833\n",
            "Epoch 44/50\n",
            "1080/1080 [==============================] - 4s 4ms/step - loss: 0.2068 - acc: 0.9870\n",
            "Epoch 45/50\n",
            "1080/1080 [==============================] - 4s 4ms/step - loss: 0.1698 - acc: 0.9954\n",
            "Epoch 46/50\n",
            "1080/1080 [==============================] - 4s 4ms/step - loss: 0.1991 - acc: 0.9935\n",
            "Epoch 47/50\n",
            "1080/1080 [==============================] - 4s 4ms/step - loss: 0.1856 - acc: 0.9917\n",
            "Epoch 48/50\n",
            "1080/1080 [==============================] - 4s 4ms/step - loss: 0.1863 - acc: 0.9926\n",
            "Epoch 49/50\n",
            "1080/1080 [==============================] - 4s 3ms/step - loss: 0.1907 - acc: 0.9880\n",
            "Epoch 50/50\n",
            "1080/1080 [==============================] - 4s 4ms/step - loss: 0.1680 - acc: 0.9954\n",
            "1080/1080 [==============================] - 30s 28ms/step\n",
            "Test Accuracy = 0.9935185185185185\n",
            "120/120 [==============================] - 0s 1ms/step\n",
            "Test Accuracy = 0.95\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}